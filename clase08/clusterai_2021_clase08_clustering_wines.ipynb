{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "__Universidad Tecnológica Nacional, Buenos Aires__<br/>\n",
    "__Ingeniería Industrial__<br/>\n",
    "__Cátedra de Ciencia de Datos - Curso I5521 - Turno sabado mañana__<br/>\n",
    "__clase_08: Practica Clustering: Wine Dataset__<br/>\n",
    "__Elaborado por: Nicolas Aguirre__<br/>\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias para trabajar.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Importamos librerias de Clustering\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.metrics import silhouette_score, rand_score\n",
    "# Importamos librerias de PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repositorio del Dataset**\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Wine\n",
    "\n",
    "**Wine Data Set:**\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de columnas\n",
    "names_col = ['G','Alcohol','Malic acid','Ash','Alcalinity of ash','Magnesium','Total phenols',\n",
    "             'Flavanoids','Nonflavanoid phenols','Proanthocyanins','Color intensity','Hue',\n",
    "             'OD280/OD315 of diluted wines','Proline']\n",
    "\n",
    "wine_df = pd.read_csv('wine.data', delimiter=',', names=names_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wine_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las features que corresponden a X\n",
    "x = wine_df.iloc[:,1:]\n",
    "y = wine_df.iloc[:,0]\n",
    "display(x.head())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a crear un dataframe para guardar los resultados\n",
    "results_df = pd.DataFrame(columns=['Cluster','Rand_','Sil_'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos un autoscaling con los datos, para todas las features\n",
    "scaler = StandardScaler().fit(x)\n",
    "xscal = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dist_cent = []\n",
    "sil_list = []\n",
    "rand_list = []\n",
    "for k in range(2, 10):\n",
    "    # Creamos el objecto de cluster y lo fiteamos en la misma linea utilizado xscal\n",
    "    kmeans = KMeans(n_clusters=k, random_state=1).fit(xscal)\n",
    "    centers_i = kmeans.cluster_centers_ # Centroide de cada cluster\n",
    "    labels_i = kmeans.labels_ # Labels de cada muestra    \n",
    "    # Silhouttte Score\n",
    "    sil_score_i = silhouette_score(xscal,labels_i)\n",
    "    sil_list.append(sil_score_i)        \n",
    "    # Rand_Index\n",
    "    rand_index_i = rand_score(y,labels_i)\n",
    "    rand_list.append(rand_index_i)\n",
    "    dist_cent.append(kmeans.inertia_)    \n",
    "# Plot de metricas\n",
    "fig, axs = plt.subplots(1,3,figsize=(15,5))    \n",
    "axs[0].plot(range(2, 10), dist_cent, marker='s');\n",
    "axs[0].set_xlabel('N° K')\n",
    "axs[0].set_ylabel('Sum of squared distances')\n",
    "# Silhoute plot\n",
    "axs[1].plot(range(2, 10), sil_list, marker='s');\n",
    "axs[1].set_xlabel('N° K')\n",
    "axs[1].set_ylabel('Silhouette')\n",
    "# Rand Index plot\n",
    "axs[2].plot(range(2, 10), rand_list, marker='s');\n",
    "axs[2].set_xlabel('N° K')\n",
    "axs[2].set_ylabel('Rand Index')    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.C.A.\n",
    "\n",
    "\n",
    "**Generamos un PCA con los datos luego del autoscaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la cantidad de componentes\n",
    "n_comps = 13\n",
    "components = range(1,n_comps + 1)\n",
    "#Creamos el objeto PCA\n",
    "pca = PCA(n_components=n_comps)\n",
    "\n",
    "# Ajustamos\n",
    "pca.fit(xscal)\n",
    "# Transformamos\n",
    "xpca = pca.transform(xscal)\n",
    "\n",
    "# Porcentaje de la varianza explicada por cada Principal Component (PC)\n",
    "eigenvalues = pca.explained_variance_ratio_\n",
    "\n",
    "# Suma acumulada\n",
    "eigenvalues_acum = pca.explained_variance_ratio_.cumsum() \n",
    "\n",
    "# Graficamos\n",
    "# Eje Izquierdo\n",
    "fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "ax1.set_xlabel('Componentes Principales',fontsize=20)\n",
    "ax1.set_ylabel('Varianza Explicada', color='k',fontsize=20)\n",
    "ax1.bar(components, eigenvalues, color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Eje derecho\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax2.set_ylabel('Varianza Acumulada', color='k',fontsize=20) \n",
    "ax2.plot(components, eigenvalues_acum, color='red') \n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvectors ($\\mathbf v$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De la libreria:\n",
    "# 'Principal axes in feature space, representing the directions of maximum variance in the data'\n",
    "# The components are sorted by explained_variance_\n",
    "pd.DataFrame(pca.components_[0:n_comps,:],columns=x.columns)\n",
    "\n",
    "# En criollo:\n",
    "# Es la direccion de los ejes de cada componente (autovectores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scatter plot de los datos, solamente con 2 PC\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.scatter(xpca[:,0],xpca[:,1])    \n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.title('Figura de PC1 y PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta: Que cantidad de clusters seleccionariamos? Porque?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un modelo de K means con ##RESPONDER## clusters con los datos autoscalados\n",
    "rta = ##RESPONDER##\n",
    "kmeans = KMeans(n_clusters = rta,\n",
    "                random_state = 10).fit(xscal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizamos los centroides finales de cada cluster\n",
    "centers = kmeans.cluster_centers_\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scatter plot de muestras y centroides con 2 PC: segun Cluster verdadero vs Clustering con K-Means\n",
    "\n",
    "#Verdadero\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.scatter(xpca[:,0],xpca[:,1],c=wine_df['G'].astype(float))    \n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.title('Clustering Verdadero')\n",
    "# K-Means\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.scatter(xpca[:,0],xpca[:,1],c=kmeans.labels_.astype(float))\n",
    "plt.scatter(centers[:,0], centers[:,1], marker=\"x\", color='r',s=150)\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.title('Clustering K-Means')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA:**\n",
    "\n",
    "**¿Son correctos los centroides?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Silhouttte Score\n",
    "sil_score = silhouette_score(xscal,kmeans.labels_)\n",
    "# Rand_Index\n",
    "rand_index = rand_score(y,kmeans.labels_)\n",
    "\n",
    "#Guardamos los resultados\n",
    "results_df = results_df.append({'Cluster':'Kmeans',\n",
    "                                'Rand_':rand_index,\n",
    "                                'Sil_':sil_score},ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA + K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora vamos dejar de usar las variables originales.**\n",
    "\n",
    "**Vamos a clusterizar con lo que nos puedan explicar UNICAMENTE las primeras 2 PC, y compararemos los resultados.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de PC quer queremos\n",
    "reduced_dim = 2\n",
    "# Definimos nuetro nuevo X de dimension reducida\n",
    "xpca_rd = xpca[:,0:reduced_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos el modelo PCA + K-means\n",
    "kmeans_rd = KMeans(n_clusters=3, \n",
    "                   random_state=10).fit(xpca_rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualizamos los centroides finales de cada cluster\n",
    "centers_rd = kmeans_rd.cluster_centers_\n",
    "centers_rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatter plot con 2 PC:**\n",
    "\n",
    "**Cluster verdadero vs Clustering con PCA+K-Means**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Verdadero\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.scatter(xpca[:,0],xpca[:,1],c=wine_df['G'].astype(float))    \n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.title('Clustering Verdadero')\n",
    "# PCA + K-Means\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.scatter(xpca_rd[:,0],xpca_rd[:,1],c=kmeans_rd.labels_.astype(float))\n",
    "plt.scatter(centers_rd[:,0], centers_rd[:,1], marker=\"x\", color='r',s=150)\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.title('Clustering K-means+RD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA:**\n",
    "\n",
    "**¿Y aca que sucedió?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouttte Score\n",
    "sil_score = silhouette_score(xpca_rd,kmeans_rd.labels_)\n",
    "# Rand_Index\n",
    "rand_index = rand_score(y,kmeans_rd.labels_)\n",
    "\n",
    "#Guardamos los resultados\n",
    "results_df = results_df.append({'Cluster':'2 PC + Kmeans',\n",
    "                                'Rand_':rand_index,\n",
    "                                'Sil_':sil_score},ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pca.components_[0:reduced_dim,:],columns=x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cantidad de PC quer queremos\n",
    "reduced_dim = 3\n",
    "xpca_rd = xpca[:,0:reduced_dim]\n",
    "# Generamos el modelo PCA + K-means \n",
    "kmeans_rd = KMeans(n_clusters=3, \n",
    "                   random_state=10).fit(xpca_rd)\n",
    "centers_rd = kmeans_rd.cluster_centers_\n",
    "centers_rd\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter3D(xpca[:,0], xpca[:,1],xpca[:,3], c=kmeans_rd.labels_)\n",
    "ax.scatter3D(centers_rd[:,0], centers_rd[:,1],centers_rd[:,2], marker=\"o\", color='r',s=150)\n",
    "\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouttte Score\n",
    "sil_score = silhouette_score(xpca_rd,kmeans_rd.labels_)\n",
    "# Rand_Index\n",
    "rand_index = rand_score(y,kmeans_rd.labels_)\n",
    "\n",
    "#Guardamos los resultados\n",
    "results_df = results_df.append({'Cluster':'3 PC + Kmeans',\n",
    "                                'Rand_':rand_index,\n",
    "                                'Sil_':sil_score},ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:**\n",
    "\n",
    "**Que Conclusiones sacamos ??**\n",
    "\n",
    "**Cual es la cantidad maxima de PC que podriamos usar? Porque?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Jerárquico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# 3 PC\n",
    "reduced_dim = 3\n",
    "xpca_rd = xpca[:,0:reduced_dim]\n",
    "\n",
    "# Definimos el linkage\n",
    "Z = linkage(xpca_rd, method = 'ward',metric='euclidean')\n",
    "# Threshold (Similaridad)\n",
    "dist_cluster = 12\n",
    "plt.figure(figsize=(25, 10))\n",
    "dendrogram(Z,color_threshold=dist_cluster)\n",
    "plt.axhline(c='k',linestyle='--', y=dist_cluster)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "dist_cluster = 12\n",
    "plt.figure(figsize=(25, 10))\n",
    "dendrogram(Z,color_threshold=dist_cluster)\n",
    "plt.axhline(c='k',linestyle='--', y=dist_cluster)\n",
    "plt.show()\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=None, distance_threshold =dist_cluster,\n",
    "                                  affinity='euclidean',\n",
    "                                  linkage='ward')\n",
    "cluster.fit_predict(xpca_rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter3D(xpca[:,0], xpca[:,1],xpca[:,3], c=cluster.labels_)\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_score = silhouette_score(xpca_rd,cluster.labels_)\n",
    "# Rand_Index\n",
    "rand_index = rand_score(y,cluster.labels_)\n",
    "\n",
    "#Guardamos los resultados\n",
    "results_df = results_df.append({'Cluster':str( reduced_dim) +  ' PC + Hierarchy ',\n",
    "                                'Rand_':rand_index,\n",
    "                                'Sil_':sil_score},ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preguntas ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![meme](https://memegenerator.net/img/instances/72560208/one-does-not-simply-run-principal-component-analysis-on-a-data-set-with-106-rows-and-103-variables.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recontruccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Si quisieramos volver a nuestro espacio original, consideremos que:**\n",
    "\n",
    "$Z = X \\cdot \\mathbf{V} \\rightarrow \\hat X = Z \\cdot \\mathbf{V}^T$\n",
    "\n",
    "siendo $Z$ la proyeccion de X en el nuevo subspace.\n",
    "\n",
    "Como vimos en la clase, los datos tienen que ser centrados (como minimo!)\n",
    "\n",
    "Para cumplir con las ecuaciones y volver a tener nuestra $\\hat X$, deberiamos sumarle las medias ...\n",
    "\n",
    "**A)** $\\hat X = Z \\cdot \\mathbf{V}^T + \\mu$\n",
    "\n",
    "Pero en nuestro caso Standarizamos los datos ($\\mu = 0, \\sigma = 1$). Entonces debemos re escalar teniendo en cuenta $\\sigma$ antes de sumar $\\mu$.\n",
    "\n",
    "**B)** $\\hat X = ( Z  \\cdot \\mathbf{V}^T) \\cdot \\sigma + \\mu $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mu = np.mean(x, axis=0)\n",
    "std = np.std(x, axis=0)[:,np.newaxis].T\n",
    "\n",
    "# 2 PCA\n",
    "reduced_dim = 2\n",
    "xpca_rd = xpca[:,0:reduced_dim]\n",
    "x_rec = np.dot(xpca_rd, pca.components_[0:reduced_dim,:])\n",
    "x_rec = x_rec * std\n",
    "x_rec += mu\n",
    "\n",
    "x_rec_df = pd.DataFrame(x_rec,columns=x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples de la reconstruccion\n",
    "sample = np.random.randint(0,high=x.shape[0])\n",
    "\n",
    "display(x.iloc[sample,:].to_frame().transpose())\n",
    "display(x_rec_df.iloc[sample,:].to_frame().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumen**:\n",
    "\n",
    "* Cuando los datos son centrados, la reconstruccion se hace teniendo en cuenta que:\n",
    "\n",
    "**A)**  $\\hat X = Z \\cdot \\mathbf{V}^T + \\mu $\n",
    "\n",
    "\n",
    "* Cuando ademas los datos son standarizados, la reconstruccion se hace teniendo en cuenta que:\n",
    "\n",
    "**B)**   $\\hat X = (Z \\cdot \\mathbf{V}^T) \\cdot \\sigma  + \\mu $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preguntas:**\n",
    "\n",
    "**Cuando debemos centrar y cuando estandarizar?**\n",
    "\n",
    "**La presencia de outliers puede modificar el resultado del PCA? Porque?**\n",
    "\n",
    "**Podemos hacer PCA sobre features categoricas?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
